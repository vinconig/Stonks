{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91d149a7",
   "metadata": {},
   "source": [
    "# Import libraries and dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b66f410",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "from kagglehub import KaggleDatasetAdapter\n",
    "from analysis_helpers import assign_combined_bucket; analyze_stocks\n",
    "import pandas as pd\n",
    "import utils\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c3cdc9",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ceea4257",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4s/_4bl0c291990qqkpvgrj459r0000gn/T/ipykernel_13919/1772646487.py:5: DeprecationWarning: Use dataset_load() instead of load_dataset(). load_dataset() will be removed in a future version.\n",
      "  df = kagglehub.load_dataset(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 records:           day  MMM_high   MMM_low  MMM_open  MMM_close  MMM_volume  \\\n",
      "0  2000-01-03  48.25000  47.03125  48.03125    47.1875   2173400.0   \n",
      "1  2000-01-04  47.40625  45.31250  46.43750    45.3125   2713800.0   \n",
      "2  2000-01-05  48.12500  45.56250  45.56250    46.6250   3699400.0   \n",
      "3  2000-01-06  51.25000  47.15625  47.15625    50.3750   5975800.0   \n",
      "4  2000-01-07  51.90625  49.96875  50.56250    51.3750   4101200.0   \n",
      "\n",
      "   MMM_adj_close   ABT_high    ABT_low   ABT_open  ...  ZION_open  ZION_close  \\\n",
      "0      27.179523  16.160433  15.599306  15.823756  ...   59.03125     55.5000   \n",
      "1      26.099533  15.599306  15.150405  15.459024  ...   54.62500     52.8125   \n",
      "2      26.855530  15.402911  15.066236  15.066236  ...   52.75000     52.7500   \n",
      "3      29.015484  15.823756  15.178461  15.262630  ...   52.75000     53.5000   \n",
      "4      29.591490  16.272657  15.487080  15.487080  ...   53.75000     53.6250   \n",
      "\n",
      "   ZION_volume  ZION_adj_close  ZTS_high  ZTS_low  ZTS_open  ZTS_close  \\\n",
      "0    1199600.0       39.500340       NaN      NaN       NaN        NaN   \n",
      "1     816100.0       37.587597       NaN      NaN       NaN        NaN   \n",
      "2    1124700.0       37.543118       NaN      NaN       NaN        NaN   \n",
      "3    1112100.0       38.076908       NaN      NaN       NaN        NaN   \n",
      "4     782000.0       38.165886       NaN      NaN       NaN        NaN   \n",
      "\n",
      "   ZTS_volume  ZTS_adj_close  \n",
      "0         NaN            NaN  \n",
      "1         NaN            NaN  \n",
      "2         NaN            NaN  \n",
      "3         NaN            NaN  \n",
      "4         NaN            NaN  \n",
      "\n",
      "[5 rows x 3031 columns]\n"
     ]
    }
   ],
   "source": [
    "# Set the path to the file you'd like to load\n",
    "file_path = \"sp500_data.csv\"\n",
    "\n",
    "# Load the latest version\n",
    "df = kagglehub.load_dataset(\n",
    "  KaggleDatasetAdapter.PANDAS,\n",
    "  \"shannanl/sp500-dataset\",\n",
    "  file_path,\n",
    ")\n",
    "df.rename(columns={df.columns[0]: \"day\"}, inplace=True)\n",
    "date_lookup = dict(enumerate(df[\"day\"]))\n",
    "print(\"First 5 records:\", df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c5eb92",
   "metadata": {},
   "source": [
    "First, lets analyze which stocks we should focus on. For that, we create buckets in regards to high/low liquidity/volatility, to see how model performance correlates to these stock attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77436bb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High Volatility / High Liquidity: ['KEY', 'VIAC', 'CCL', 'AAPL', 'GILD', 'FOXA', 'C', 'FITB', 'F', 'RF', 'HBAN', 'MPC', 'QCOM', 'CARR', 'ADBE', 'EOG', 'NEM', 'NLOK', 'EBAY', 'MCHP', 'HBI', 'MTCH', 'EA', 'AIG', 'CTSH', 'VLO', 'ATVI', 'MRO', 'SCHW', 'CTRA', 'MS', 'CRM', 'DVN', 'XLNX', 'GPS', 'AMAT', 'AES', 'HAL', 'NCLH', 'BBY', 'DOW', 'MNST', 'GLW', 'WMB', 'CF', 'DHI', 'STX', 'PHM', 'AMZN', 'MGM', 'JNPR', 'UAA', 'DAL', 'LVS', 'NTAP', 'FCX', 'TWTR', 'NFLX', 'TSLA', 'MU', 'NVDA', 'UAL', 'AAL', 'AMD', 'MRNA']\n",
      "High Volatility / Low Liquidity: ['RL', 'CMG', 'GNRC', 'KSU', 'ODFL', 'TYL', 'SIVB', 'PVH', 'MKTX', 'ANET', 'LYV', 'MPWR', 'IPGP', 'ULTA', 'PAYC', 'CDAY', 'PTC', 'SBAC', 'URI', 'EQIX', 'BKNG', 'DXCM', 'ILMN', 'ALGN', 'ABMD', 'REGN', 'INCY']\n",
      "Low Volatility / High Liquidity: ['JNJ', 'PEP', 'PG', 'KO', 'NEE', 'MDLZ', 'MCD', 'WMT', 'PM', 'VZ', 'ABT', 'PFE', 'T', 'MDT', 'XOM', 'BAX', 'MO', 'IBM', 'EXC', 'LLY', 'MRK', 'CVX', 'RTX', 'BMY', 'KHC', 'ABBV', 'V', 'UNP', 'KMI']\n",
      "Low Volatility / Low Liquidity: ['WEC', 'AEE', 'DTE', 'VRSK', 'MKC', 'ES', 'LNT', 'ATO', 'AWK', 'PNW', 'HSY', 'CLX', 'BF-B', 'EVRG', 'GPC', 'CHD', 'ETR', 'ECL', 'BDX', 'SRE', 'SJM', 'AJG', 'BRO', 'ALLE', 'CBOE', 'WRB', 'WLTW', 'XYL', 'MAA', 'BR', 'CINF', 'ESS', 'IFF', 'GL', 'IQV', 'PSA', 'RE', 'O', 'ARE', 'AVB', 'FRC', 'TFX', 'FRT', 'XRAY', 'APD', 'LH', 'HII', 'AZO', 'EFX', 'CDW', 'BXP', 'TAP', 'LDOS', 'AME', 'DGX', 'IEX', 'CHTR', 'NWS', 'GWW', 'AIZ', 'WST']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vinconig/Desktop/PUCP/IAA/Repos/Stonks/analysis_helpers.py:26: FutureWarning: The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  returns = df[close_col].pct_change()\n"
     ]
    }
   ],
   "source": [
    "bucket_df = analyze_stocks(df)\n",
    "\n",
    "\n",
    "# Extract only the first 5 tickers for each quadrant\n",
    "\n",
    "HV_HL = bucket_df[(bucket_df[\"vol_bucket\"] == \"high\") & \n",
    "                  (bucket_df[\"liq_bucket\"] == \"high\")].index.tolist()[:5]\n",
    "\n",
    "HV_LL = bucket_df[(bucket_df[\"vol_bucket\"] == \"high\") & \n",
    "                  (bucket_df[\"liq_bucket\"] == \"low\")].index.tolist()[:5]\n",
    "\n",
    "LV_HL = bucket_df[(bucket_df[\"vol_bucket\"] == \"low\") & \n",
    "                  (bucket_df[\"liq_bucket\"] == \"high\")].index.tolist()[:5]\n",
    "\n",
    "LV_LL = bucket_df[(bucket_df[\"vol_bucket\"] == \"low\") & \n",
    "                  (bucket_df[\"liq_bucket\"] == \"low\")].index.tolist()[:5]\n",
    "\n",
    "# Print the lists\n",
    "print(\"High Volatility / High Liquidity:\", HV_HL)\n",
    "print(\"High Volatility / Low Liquidity:\", HV_LL)\n",
    "print(\"Low Volatility / High Liquidity:\", LV_HL)\n",
    "print(\"Low Volatility / Low Liquidity:\", LV_LL)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274a5524",
   "metadata": {},
   "source": [
    "Load all available stock history of a S&P 500 company of your choosing into a separate dataframe. Note: we transform the date to a timestep, because we dont want to train the model on the actual physical point in time. we just need to give it sequential context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419c4e88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple stock data:    timestep  AAPL_high  AAPL_low  AAPL_open  AAPL_close  AAPL_volume  \\\n",
      "0         0   1.004464  0.907924   0.936384    0.999442  535796800.0   \n",
      "1         1   0.987723  0.903460   0.966518    0.915179  512377600.0   \n",
      "2         2   0.987165  0.919643   0.926339    0.928571  778321600.0   \n",
      "3         3   0.955357  0.848214   0.947545    0.848214  767972800.0   \n",
      "4         4   0.901786  0.852679   0.861607    0.888393  460734400.0   \n",
      "\n",
      "   AAPL_adj_close  \n",
      "0        0.858137  \n",
      "1        0.785788  \n",
      "2        0.797286  \n",
      "3        0.728291  \n",
      "4        0.762789  \n"
     ]
    }
   ],
   "source": [
    "df_apple = utils.load_comp_data(df, \"AAPL\")\n",
    "print(\"Apple stock data:\", df_apple.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd0aba7",
   "metadata": {},
   "source": [
    "However, of course, we can always get the actual day back, if we need to plot or else, by using the 'timestep' value. This will also work after data was transformed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "18607f43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2000-03-03'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_lookup[42]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f95c8850",
   "metadata": {},
   "source": [
    "Apply feature engineering techniques to stock. As many features use a rolling window, you can decide if you want to cut the first rows, where those values are not calculated using data from the entirety of the window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "27463d70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple stock data with feature engineering:       timestep   AAPL_high    AAPL_low   AAPL_open  AAPL_close  AAPL_volume  \\\n",
      "5476      5477  144.179993  142.559998  144.029999  142.899994   58718700.0   \n",
      "5477      5478  144.809998  141.809998  142.270004  142.809998   64452200.0   \n",
      "5478      5479  143.250000  141.039993  143.229996  141.509995   73035900.0   \n",
      "5479      5480  141.399994  139.199997  141.240005  140.910004   78762700.0   \n",
      "5480      5481  143.880005  141.509995  142.110001  143.759995   69907100.0   \n",
      "\n",
      "      AAPL_adj_close  log_return  true_range    rsd_20    ntv_20  \\\n",
      "5476      142.899994   -0.007877    1.619995  0.010277  0.686338   \n",
      "5477      142.809998    0.003788    3.000000  0.010273  0.770443   \n",
      "5478      141.509995   -0.012081    2.210007  0.010092  0.892390   \n",
      "5479      140.910004   -0.002339    2.309998  0.010041  0.965027   \n",
      "5480      143.759995    0.011544    2.970001  0.010429  0.855544   \n",
      "\n",
      "      log_next_day_max_return  \n",
      "5476                 0.013277  \n",
      "5477                 0.003076  \n",
      "5478                -0.000778  \n",
      "5479                 0.020858  \n",
      "5480                 0.007899  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2000-01-04'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "window_size = 20\n",
    "df_apple_fe = utils.compute_features(df_apple, w=window_size, cut=False)\n",
    "print(\"Apple stock data with feature engineering:\", df_apple_fe.tail())\n",
    "date_lookup[df_apple_fe.iloc[0][\"timestep\"]]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IAA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
