{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91d149a7",
   "metadata": {},
   "source": [
    "# Import libraries and dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b66f410",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "from kagglehub import KaggleDatasetAdapter\n",
    "from analysis_helpers import assign_combined_bucket \n",
    "from analysis_helpers import analyze_stocks\n",
    "import pandas as pd\n",
    "import utils\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c3cdc9",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ceea4257",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4s/_4bl0c291990qqkpvgrj459r0000gn/T/ipykernel_13919/1772646487.py:5: DeprecationWarning: Use dataset_load() instead of load_dataset(). load_dataset() will be removed in a future version.\n",
      "  df = kagglehub.load_dataset(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 records:           day  MMM_high   MMM_low  MMM_open  MMM_close  MMM_volume  \\\n",
      "0  2000-01-03  48.25000  47.03125  48.03125    47.1875   2173400.0   \n",
      "1  2000-01-04  47.40625  45.31250  46.43750    45.3125   2713800.0   \n",
      "2  2000-01-05  48.12500  45.56250  45.56250    46.6250   3699400.0   \n",
      "3  2000-01-06  51.25000  47.15625  47.15625    50.3750   5975800.0   \n",
      "4  2000-01-07  51.90625  49.96875  50.56250    51.3750   4101200.0   \n",
      "\n",
      "   MMM_adj_close   ABT_high    ABT_low   ABT_open  ...  ZION_open  ZION_close  \\\n",
      "0      27.179523  16.160433  15.599306  15.823756  ...   59.03125     55.5000   \n",
      "1      26.099533  15.599306  15.150405  15.459024  ...   54.62500     52.8125   \n",
      "2      26.855530  15.402911  15.066236  15.066236  ...   52.75000     52.7500   \n",
      "3      29.015484  15.823756  15.178461  15.262630  ...   52.75000     53.5000   \n",
      "4      29.591490  16.272657  15.487080  15.487080  ...   53.75000     53.6250   \n",
      "\n",
      "   ZION_volume  ZION_adj_close  ZTS_high  ZTS_low  ZTS_open  ZTS_close  \\\n",
      "0    1199600.0       39.500340       NaN      NaN       NaN        NaN   \n",
      "1     816100.0       37.587597       NaN      NaN       NaN        NaN   \n",
      "2    1124700.0       37.543118       NaN      NaN       NaN        NaN   \n",
      "3    1112100.0       38.076908       NaN      NaN       NaN        NaN   \n",
      "4     782000.0       38.165886       NaN      NaN       NaN        NaN   \n",
      "\n",
      "   ZTS_volume  ZTS_adj_close  \n",
      "0         NaN            NaN  \n",
      "1         NaN            NaN  \n",
      "2         NaN            NaN  \n",
      "3         NaN            NaN  \n",
      "4         NaN            NaN  \n",
      "\n",
      "[5 rows x 3031 columns]\n"
     ]
    }
   ],
   "source": [
    "# Set the path to the file you'd like to load\n",
    "file_path = \"sp500_data.csv\"\n",
    "\n",
    "# Load the latest version\n",
    "df = kagglehub.load_dataset(\n",
    "  KaggleDatasetAdapter.PANDAS,\n",
    "  \"shannanl/sp500-dataset\",\n",
    "  file_path,\n",
    ")\n",
    "df.rename(columns={df.columns[0]: \"day\"}, inplace=True)\n",
    "date_lookup = dict(enumerate(df[\"day\"]))\n",
    "print(\"First 5 records:\", df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c5eb92",
   "metadata": {},
   "source": [
    "First, lets analyze which stocks we should focus on. For that, we create buckets in regards to high/low liquidity/volatility, to see how model performance correlates to these stock attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "77436bb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High Volatility / High Liquidity: ['KEY', 'VIAC', 'CCL', 'AAPL', 'GILD']\n",
      "High Volatility / Low Liquidity: ['RL', 'CMG', 'GNRC', 'KSU', 'ODFL']\n",
      "Low Volatility / High Liquidity: ['JNJ', 'PEP', 'PG', 'KO', 'NEE']\n",
      "Low Volatility / Low Liquidity: ['WEC', 'AEE', 'DTE', 'VRSK', 'MKC']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vinconig/Desktop/PUCP/IAA/Repos/Stonks/analysis_helpers.py:26: FutureWarning: The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  returns = df[close_col].pct_change()\n"
     ]
    }
   ],
   "source": [
    "bucket_df = analyze_stocks(df)\n",
    "\n",
    "\n",
    "# Extract only the first 5 tickers for each quadrant\n",
    "\n",
    "HV_HL = bucket_df[(bucket_df[\"vol_bucket\"] == \"high\") & \n",
    "                  (bucket_df[\"liq_bucket\"] == \"high\")].index.tolist()[:5]\n",
    "\n",
    "HV_LL = bucket_df[(bucket_df[\"vol_bucket\"] == \"high\") & \n",
    "                  (bucket_df[\"liq_bucket\"] == \"low\")].index.tolist()[:5]\n",
    "\n",
    "LV_HL = bucket_df[(bucket_df[\"vol_bucket\"] == \"low\") & \n",
    "                  (bucket_df[\"liq_bucket\"] == \"high\")].index.tolist()[:5]\n",
    "\n",
    "LV_LL = bucket_df[(bucket_df[\"vol_bucket\"] == \"low\") & \n",
    "                  (bucket_df[\"liq_bucket\"] == \"low\")].index.tolist()[:5]\n",
    "\n",
    "# Print the lists\n",
    "print(\"High Volatility / High Liquidity:\", HV_HL)\n",
    "print(\"High Volatility / Low Liquidity:\", HV_LL)\n",
    "print(\"Low Volatility / High Liquidity:\", LV_HL)\n",
    "print(\"Low Volatility / Low Liquidity:\", LV_LL)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274a5524",
   "metadata": {},
   "source": [
    "Load all available stock history of a S&P 500 company of your choosing into a separate dataframe. Note: we transform the date to a timestep, because we dont want to train the model on the actual physical point in time. we just need to give it sequential context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "419c4e88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple stock data:    timestep  AAPL_high  AAPL_low  AAPL_open  AAPL_close  AAPL_volume  \\\n",
      "0         0   1.004464  0.907924   0.936384    0.999442  535796800.0   \n",
      "1         1   0.987723  0.903460   0.966518    0.915179  512377600.0   \n",
      "2         2   0.987165  0.919643   0.926339    0.928571  778321600.0   \n",
      "3         3   0.955357  0.848214   0.947545    0.848214  767972800.0   \n",
      "4         4   0.901786  0.852679   0.861607    0.888393  460734400.0   \n",
      "\n",
      "   AAPL_adj_close  \n",
      "0        0.858137  \n",
      "1        0.785788  \n",
      "2        0.797286  \n",
      "3        0.728291  \n",
      "4        0.762789  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vinconig/Desktop/PUCP/IAA/Repos/Stonks/utils.py:39: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  result.fillna(method='ffill', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "df_apple = utils.load_comp_data(df, \"AAPL\")\n",
    "print(\"Apple stock data:\", df_apple.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd0aba7",
   "metadata": {},
   "source": [
    "However, of course, we can always get the actual day back, if we need to plot or else, by using the 'timestep' value. This will also work after data was transformed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "18607f43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2000-03-03'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_lookup[42]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f95c8850",
   "metadata": {},
   "source": [
    "Apply feature engineering techniques to stock. As many features use a rolling window, you can decide if you want to cut the first rows, where those values are not calculated using data from the entirety of the window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "27463d70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple stock data with feature engineering:       timestep  AAPL_high  AAPL_low  AAPL_open  AAPL_close  AAPL_volume  \\\n",
      "5456      5477  -0.593097 -0.194214  -0.233947   -0.538862    -1.263644   \n",
      "5457      5478  -0.289042 -0.358134  -0.702262   -0.493662    -0.899623   \n",
      "5458      5479  -0.848506 -0.558214  -0.297249   -0.877397    -0.427938   \n",
      "5459      5480  -1.553588 -1.145604  -0.967597   -1.037309    -0.138639   \n",
      "5460      5481  -0.323117 -0.158679  -0.546650    0.274642    -0.575012   \n",
      "\n",
      "      log_return  true_range    rsd_20    ntv_20  ...  bollinger_mid  \\\n",
      "5456   -0.580691   -1.391396 -2.480652 -1.217181  ...      -1.966097   \n",
      "5457    0.501146    0.031912 -2.115457 -0.829901  ...      -1.827024   \n",
      "5458   -1.076568   -0.714177 -1.948051 -0.316907  ...      -1.714997   \n",
      "5459   -0.084412   -0.561067 -1.751735 -0.017193  ...      -1.649681   \n",
      "5460    1.205837    0.086429 -1.299038 -0.429253  ...      -1.551939   \n",
      "\n",
      "      bollinger_upper  bollinger_lower  bollinger_width  bollinger_percent_b  \\\n",
      "5456        -2.571103        -0.996733        -0.998399             1.110811   \n",
      "5457        -2.323619        -0.865878        -1.331640             1.219799   \n",
      "5458        -2.084672        -0.827456        -1.433247             0.445438   \n",
      "5459        -1.981309        -0.733286        -1.647289             0.180068   \n",
      "5460        -1.909303        -0.476234        -1.943495             2.413005   \n",
      "\n",
      "         rsi_w       obv  volume_z  candle_body  candle_range_ratio  \n",
      "5456 -0.096655  0.565762 -1.426418    -0.574347           -1.274717  \n",
      "5457 -0.192416 -0.031948 -0.937242     0.501806            0.468281  \n",
      "5458 -0.128857 -0.804448 -0.348460    -1.070846           -1.438728  \n",
      "5459 -0.420508 -1.585818  0.011755    -0.080138           -0.152514  \n",
      "5460  0.550171 -0.670896 -0.483383     1.207771            1.422966  \n",
      "\n",
      "[5 rows x 31 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2000-02-02'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "window_size = 20\n",
    "df_apple_fe = utils.compute_features(df_apple, w=window_size, cut=False)\n",
    "print(\"Apple stock data with feature engineering:\", df_apple_fe.tail())\n",
    "date_lookup[df_apple_fe.iloc[0][\"timestep\"]]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IAA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
